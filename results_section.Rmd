---
title: "Results section"
date: "`r format(Sys.time(), '%d/%m/%y')`"
output:
  #html_document:
  bookdown::html_document2:  
    self_contained: true
    highlight: tango
    df_print: paged
    code_folding: hide
    toc: yes
    toc_depth: 2
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: true
editor_options:
  chunk_output_type: console
---

```{r stp1, echo=FALSE}
library(knitr)
opts_chunk$set(echo=FALSE, fig.align='center', fig.path='figure/', progress=FALSE, verbose=FALSE, message = FALSE, warning = FALSE, error = FALSE, fig.width = 8, fig.height = 5.5)
```



```{r, echo=FALSE}

suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(xlsx))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(pheatmap))


```


```{r, echo=FALSE}
data = read.xlsx("ELIXIR SCO Training survey (rÃ©ponses).xlsx", sheetIndex = 1, header = F)
colnames = as.character(data[1,])
data = data[-1,]

```


# Respondents

First, some statistics on the respondents of the survey. In total we had `r nrow(data)` unique responses. 

## Responses per country

Country of origin of the respondents is shown in Figure \@ref(fig:n_response). We have up to five responses from many countries, but there are also many countries where we did not manage to get any reponses so we do not expect this survey to give a fully complete picture of the stat of teaching in the field. 

```{r n_response, echo=FALSE, fig.cap="Number of respondends per country"}

data$Country = data[,4]
data$Country = sub("ELIXIR-","", data$Country)
data$Country = sub("FRANCE","France", data$Country)
data$Country = sub("The ","", data$Country)
data$Country[grep("UK", data$Country)] = "United Kingdom"
data$Country[grep("German", data$Country)] = "Germany"
data$Country[grep("United States", data$Country)] = "USA"
data$Country[grep("INB Spain", data$Country)] = "Spain"

t = table(data$Country)
data = data[order(data$Country),]
data$nCountry = paste(data$Country, unlist(sapply(t, function(x) 1:x)), sep = "-")

tmp = data.frame(table(data$Country))
colnames(tmp) = c("Country","Counts")
ggplot(tmp, aes(x=Country,y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + theme_classic() + coord_flip()

all.countries = unique(data$Country)
```



```{r, echo=FALSE, results='hide'}
# Responses with no country
a = which(is.na(data[,5]))

b = grep("None", data[,5])

cat("No courses listed for ", paste(data$Country[c(a,b)], collapse = ", "))
```

## Percieved challenges

Two questions related to what the key challenges are in the pedagogical (Figure \@ref(fig:pedagogical)) and technical (Figure \@ref(fig:technical)) part of setting up courses. 

On the pedagogical side, the issue of having a non-uniform audience clearly stands out as a main issue. But also related to that, many see issues with selecting participants with the correct prerequisites, to help learners that are struggling and that do not have the correct prerequisites. Also, finding a good balance between practicals and lectures is a common issue. 

While on the technical side different operating systems, software installations and issues with services seems to be the largest challenges. 



```{r pedagogical, echo=FALSE, fig.cap="Percieved pedagogical challenges when teaching that the respondends have listed. Multiple choice question."}
# remove commas in the answers to split on ,
tmp1 = data[,81]
tmp1 = gsub("interactive,","interactive;",tmp1)

tmp = data.frame(sort(table(unlist(strsplit(tmp1,", ")))))
colnames(tmp) = c("Response","Counts")

# put back comma
tmp$Response = gsub(";",",", tmp$Response)

# only one "other"
other = tmp$Response[grepl("Not sure yet", tmp$Response)]
tmp$Response[grepl("Not sure yet", tmp$Response)] = "Other"

# add in linebreaks
tmp$Response = sapply(tmp$Response, function(x) paste(strwrap(x,50), collapse="\n"))

# order by size
lev = tmp$Response[!grepl("Other", tmp$Response)][order(tmp$Count[!grepl("Other", tmp$Response)], decreasing = F)]
tmp$Response = factor(tmp$Response, levels = c("Other", lev))


colnames(tmp) = c("Response","Counts")
ggplot(tmp, aes(x=Response, y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic() + theme(axis.text.y = element_text(size = 8))
```

"Other" includes: `r other`.






```{r technical, echo=FALSE, message=FALSE, results='hide', warning=FALSE,  fig.cap="Percieved technical challenges when teaching that the respondends have listed. Multiple choice question."}
#tmp = data.frame(sort(table(unlist(strsplit(data[,82],"Issues | Data")))), stringsAsFactors = F)
tmp = data.frame(sort(table(unlist(strsplit(data[,82],"Issues ")))), stringsAsFactors = F)

# remove empty
tmp = tmp[nchar(as.character(tmp$Var1))>0,]
colnames(tmp) = c("Response","Counts")

#add back the "Issues"
starts = c("on", "in", "due", "with")
is.issue = rowSums(sapply(starts, function(x) startsWith(as.character(tmp$Response),x)))
tmp$Response = as.character(tmp$Response)
tmp$Response[is.issue>0] = paste0("Issues ",as.character(tmp$Response[is.issue>0]))

other = tmp$Response[is.issue == 0]
tmp$Response[is.issue == 0] = "Other"

# add in linebreaks
tmp$Response = sapply(tmp$Response, function(x) paste(strwrap(x,60), collapse="\n"))

# order by size
lev = tmp$Response[!grepl("Other", tmp$Response)][order(tmp$Count[!grepl("Other", tmp$Response)], decreasing = F)]
tmp$Response = factor(tmp$Response, levels = c("Other", lev))

ggplot(tmp, aes(x=Response, y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic()
```

"Other" includes: `r other`.


```{r, echo=FALSE, results='hide'}
# Parse information by course

#Instead of listing results by the respondents, extract the information from each individual course. 

#For each course, parse the info in all parts of the questions, also for "Rising need" or "I can teach"

parse_course_url = function(x){
  s = strsplit(x,"\n")[[1]]
  s = gsub("Course *#[0-9] *[:-] *", "",s)
  s = s[nchar(s)>1]
  return(s)
}


options = c("Course #1", "Course #2", "Course #3", "Course #4", "Rising need", "I can teach")
#parse sections 2-11, skipping 7
section.idx = c(2:6,8:11)
section.trans = c("Teacher","Duration","nStudents", "SCO", "SRT","EntryReq","Strategies","Compute", "Topics")
names(section.trans)=section.idx

option = sapply(colnames, str_extract, "\\[.*\\]")
option = gsub("\\]", "", option)
option = gsub("\\[", "", option)
sec = sapply(colnames, str_extract ,"^\\d+")
new.name = paste(section.trans[sec],option, sep = " : ")
new.name[is.na(option)] = colnames[is.na(option)]
colnames(data) = new.name

parse_line = function(x){
  urls = parse_course_url(x[,5])
  datasets = parse_course_url(x[,37])
  email = x[,2]
  s = sapply(options, grepl, x)
  s = apply(s,2, function(y) new.name[y])
  s = lapply(s, function(y) y[!grepl("^\\d",y)]) # remove names starting with number
  
  courses = s[grepl("Course", names(s))]  
  courses = courses[sapply(courses,length)>0]
  nC = length(courses)
  if(nC == 0){
    return(list(country=x[,85],name=x[,86], needs=s$`Rising need`, urls = urls, courses = NULL, email = email))
  }
  
  names(courses) = paste(x[,86], names(courses), sep = ":")
  courses = lapply(courses, function(y) c(y, paste0("Country : ",x[,85])))
  courses = lapply(courses, function(y) c(y, paste0("Email : ",x[,2])))
  if (length(urls) != length(courses)){
    print("Different number of urls. ")
    print(email)
    print(urls)
    print(names(courses))
  }
  if (length(datasets) != length(courses)){
    print("Different number of datasets ")
    print(email)
    print(datasets)
    print(names(courses))
  }
  for (i in 1:length(courses)){
    courses[[i]] = c(courses[[i]], paste0("Url : ", urls[min(i, length(urls))]))
    courses[[i]] = c(courses[[i]], paste0("Dataset : ", datasets[min(i, length(datasets))]))
  }
  
  return(list(country=x[,85],name=x[,86], needs=s$`Rising need`, urls = urls, courses = courses))
   
}


all.data = list()
for (i in 1:nrow(data)){
  all.data[[i]] = parse_line(data[i,])
}
```

```{r, echo=FALSE, results='hide'}
#OBS! USA-1 - same course for 2019,20,21,22 - only one url.


#Comment:
#All other courses on single cell I know are on glittr.org: https://glittr.org/?search=single+cell&per_page=25&sort_by=stargazers&sort_direction=desc

#Multiple galaxyproject entries from Netherlands possibly pointing to the same course.

# One of the Dutch courses is the resource page https://www.singlecell.nl/home, it has all topics included in the list. Remove from summary stats.
```

```{r,  echo=FALSE}
courses = sapply(all.data, function(x) x$courses)
courses = unlist(courses, recursive = F)

all.opts = new.name[!grepl("^\\d", new.name)][-c(1:4)]
all.opts = all.opts[-75]

stats = Reduce(rbind,lapply(courses, function(x) all.opts %in% x))
colnames(stats) = all.opts
rownames(stats) = names(courses)
stats = stats + 0
stats = t(stats)

annot = data.frame(country = sapply(strsplit(names(courses),"-"), function(x) x[1]))
rownames(annot) = names(courses)
```


```{r, echo=FALSE}
# Topics

sel.topics = c(grep("SCO", rownames(stats)), grep("SRT", rownames(stats)), grep("Topics", rownames(stats)))



#pheatmap(stats[sel.topics,], cluster_rows = F, fontsize = 6, annotation_col = annot)
```


```{r, echo=FALSE}
# Grouped by country
course2country = lapply(courses, function(x) gsub("Country : ", "", x[grepl("Country",x)]))

tmp = data.frame(t(stats))
tmp$Country = course2country

tmp = tmp[rownames(tmp) != "Netherlands-5:Course #2",]

tmp2 = tmp %>% group_by(Country) %>% summarise_each(list(sum))

stats.country = data.frame(tmp2)
rownames(stats.country) = tmp2$Country
stats.country = stats.country[,-1]
stats.country = t((stats.country>0) + 0)

#pheatmap(stats.country[sel.topics,], cluster_rows = F, fontsize = 6)
```


```{r,  echo=FALSE}
#### Teaching methods
sel.teaching = c(grep("Strategies", rownames(stats)), grep("Compute", rownames(stats)))

#pheatmap(stats[sel.teaching,], cluster_rows = F, fontsize = 6, annotation_col = annot)

# Grouped by country
#pheatmap(stats.country[sel.teaching,], cluster_rows = F, fontsize = 6)
```


## Areas with a rising need

Areas where the respondents sees a rising need, grouped by country is shown in Figure \@ref(fig:need). This section was mixed in with multiple choice options "I teach in" and "I can teach" and it seems that many respondents did not fully understand this. Most respondents did not fill in any areas with a rising need while others have filled in a rising need for pretty much every topic. 



```{r need, fig.height=5, fig.cap="Areas where respondents see a rising need for teaching, grouped by country. SCO = Single Cell Omics, SRT = Spatially Resolved Transcriptomics"}
needs = lapply(all.data, function(x) x$needs)
countries = unlist(lapply(all.data, function(x) x$country))

s = split(needs, countries)
s = lapply(s, unlist)

all.cat = rownames(stats)[c(grep("SCO", rownames(stats)), grep("SRT", rownames(stats)))]

need.stats = Reduce(cbind, lapply(s, function(x) all.cat %in% x)) + 0
rownames(need.stats) = all.cat
colnames(need.stats) = names(s)

pheatmap(need.stats, cluster_rows = F, legend_breaks = c(0,1), legend_labels = c("no","yes"))
```



```{r, echo=FALSE}
#### Print to csv
all.courses = unlist(lapply(all.data, function(x) x$courses), recursive = F)

course.names = colnames(stats)

sel.columns = c("Country","Email","Url","Dataset")
pattern = paste(sel.columns, collapse = "|")

extra = Reduce(rbind, lapply(all.courses, function(x) x[grepl(pattern,x)]))
colnames(extra) = sel.columns


out = data.frame(cbind(extra),t(stats))
rownames(out) = colnames(stats)
write.csv(out, "parsed_courses.csv")
```

# Courses

Instead of listing results by the respondents, information was extracted about each individual course. 

Manual filtering was performed to remove duplicate course instances and examples of entries that are not really courses.
Country of origin for each course was also added manually.


```{r , echo=FALSE}
courses2 = read.table("Training_survey_parsed_courses - parsed_courses.tsv", header = T, row.names = 1, sep = "\t", quote = "", comment.char = "")

# remove duplicates and non-courses
courses2 = courses2[nchar(courses2$Is.duplicate) ==0,]
courses2 = courses2[nchar(courses2$Not.a.course) ==0,]

# revert back to the old colnames in stats, not with ...
old.names = rownames(stats)
colnames(courses2) = c(colnames(courses2)[1:13],old.names)

```


## Courses per country

First, a summary of total number of courses per country is shown in Figure \@ref(fig:ncourses). In total `r nrow(courses2)` courses are included.

```{r ncourses, fig.cap="Number of courses per country, courses that are collaborations between more than one European country is listed as European and courses with multiple countries as International" }

tmp = data.frame(table(courses2$`Country.Edited`))
colnames(tmp) = c("Country","Counts")

ggplot(tmp, aes(x=Country,y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + theme_classic() + coord_flip() + theme(axis.title.y = element_blank())

```

We only have information on the courses that the respondents of the survey provided so it may give an unfair comparison of the countries if we do not have complete coverage in responses from some countries. 




## Topics and Technologies 

To get a view of what the different courses cover, the survey included a list of putative topics and technologies for the respondents to fill in. The different technologies are divided into categories SCO (Single Cell Omics) and SRT (Spatially Resolved Transcriptomics) and we also have a list of putative topics that the courses could include. 

First all courses as shown as a heatmap grouped by similarity in topics/technologies covered (Figure \@ref(fig:topicall)). 





```{r}
sel.topics = c(grep("SCO", colnames(courses2)), grep("SRT", colnames(courses2)), grep("Topics", colnames(courses2)))

annot = data.frame(country = courses2$`Country.Edited`)
annot$country = gsub("Country : ","", annot$country)
rownames(annot) = rownames(courses2)

```

```{r topicall,  fig.cap="Overview of courses covering different topics/technologies. Red indicates that there is a course that includes the topic, blue that no course includes it. The colorbar at the top shows the country of origin for each course." }
pheatmap(t(courses2[,sel.topics]), cluster_rows = F, cluster_cols = T, fontsize = 6, annotation_col = annot, legend_breaks = c(0,1), legend_labels = c("no","yes"), show_colnames = F)

```

```{r}
tmp = data.frame(Count = sort(colSums(courses2[,sel.topics])))
tmp$Topic = factor(rownames(tmp),levels = rownames(tmp))
tmp$group = unlist(lapply(strsplit(rownames(tmp)," : "), function(x) x[1]))
```



```{r , fig.cap="Total count of courses covering different topics/technologies." , eval=FALSE}
ggplot(tmp, aes(x=Topic,y=Count, fill=group)) + geom_bar(stat="identity", width=0.5) + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())
```

Then the count of how many courses that cover each topic is shown in Figure \@ref(fig:topiccount).  Many of the basic steps in scRNAseq processing, such as quality control, dimensionality reduction, normalization and clustering, are covered by most of the courses. While topics related to image analysis are not so well covered.



```{r topiccount, fig.cap="Total count of courses covering different topics."}
ggplot(tmp[tmp$group == "Topics",], aes(x=Topic,y=Count)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())
```

Finally the count of how many courses that cover each technology is shown in Figure \@ref(fig:techcount). Almost all courses deal with scRNAseq but very few include other single cell omics. On the SRT (Spatially resolved transcriptomics) side there are in general very few courses, and those that include any SRT technology are mainly focused on spot-based methods such as 10X Visium. 


```{r techcount, fig.cap="Total count of courses covering different technologies. SCO (Single Cell Omics) and SRT (Spatially Resolved Transcriptomics)"}
ggplot(tmp[tmp$group != "Topics",], aes(x=Topic,y=Count, fill=group)) + geom_bar(stat="identity", width=0.5) + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())

# Save the plot
ggsave("figure/techcount_plot.pdf", width = 10, height = 8, dpi = 300)
```



```{r, eval=FALSE}
### Topics / Technologies - By country

tmp = courses2[,sel.topics]
tmp$country = courses2$`Country.Edited`
tmp2 = tmp %>% group_by(country) %>% summarise_each(list(sum))
tmp2 = data.frame(tmp2)
rownames(tmp2) = tmp2$country
tmp2 = tmp2[,-1]

pheatmap(t(tmp2>0)+0, cluster_rows = F, fontsize = 6, legend_breaks = c(0,1), legend_labels = c("no","yes"))

```

## Course delivery

Finally we have summarised some statistics on how courses are delivered, such as on line vs face to face, course duration, selection of participants etc. 

#### Online material {-}

We have summarised what material from the course is available on line (Figure \@ref(fig:online)). In the survey, only the question about on line lectures was included, so we have manually search all the course instances to check for on line course materials.  

A majority the courses have the exercises and lecture slides available online, often via github. However, only a third of the courses also provide recorded lectures available to the public. 

```{r online, fig.width=6, fig.height=6, fig.cap="Availability of on line material in the courses with TRUE/FALSE for available/not available and rows represent course material and columns represents lectures."}
tmp = data.frame(Online_material = grepl("Yes", courses2$Online.material), Online_lectures = grepl("Yes", courses2$Online.lectures))
tmp$Country = courses2$Country.Edited
library(grid)

#table(tmp[,1:2])
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(table(tmp[,1:2]), display_numbers = T, cluster_rows = F, cluster_cols = F, number_format = "%d", fontsize_number = 20, legend = F)

setHook("grid.newpage", NULL, "replace")
grid.text("Online Lectures", y=-0.07, gp=gpar(fontsize=16))
grid.text("Online Course Material", x=-0.07, rot=90, gp=gpar(fontsize=16))


```



```{r, fig.width=6, fig.height=8, eval=FALSE}
#Per country/course

rownames(tmp) = rownames(courses2)
annot2 = data.frame(Country = tmp$Country)
pheatmap(tmp[,1:2]+0, cluster_cols = F, annotation_row = annot, treeheight_row = 0, legend_breaks = c(0,1), legend_labels = c("no","yes"))
```

#### Teaching strategies {-}

For each course the respondents were asked to specify what teaching strategies were used in the courses, both related to techincal solutions (Figure \@ref(fig:techteach)) and to pedagogical strategies (Figure \@ref(fig:pedteach)). 

With regards to technical solutions (Figure \@ref(fig:techteach)) the most common way to deliver courses is with Rstudio, and most of the courses are based on the R programming language, while there are a few courses that instead uses python and jupyther notebooks.  For compute infrastructure many of the courses run exercises on the students own computer, but also many also have a course server. Very few courses provide a docker container or a conda recipe so in general the reproducibility of many courses would not be considered very high. 


```{r techteach, fig.cap="Computational strategies used when teaching, number of courses using each strategy."}
sel.teaching = c(grep("Strategies", colnames(courses2)), grep("Compute", colnames(courses2)))

tmp = data.frame(Count = sort(colSums(courses2[,sel.teaching])))
tmp$Group = unlist(lapply(strsplit(rownames(tmp)," : "), function(x) x[1]))
tmp = tmp[!grepl("Other",rownames(tmp)),]

tmp$Topic = gsub("Strategies : ","",rownames(tmp))
tmp$Topic = gsub("Compute : ","",tmp$Topic)
tmp$Topic = factor(tmp$Topic,levels = tmp$Topic)

ggplot(tmp[tmp$Group == "Compute",], aes(x=Topic,y=Count)) + geom_bar(stat="identity", width=0.5, fill = "red") + coord_flip()  + theme_classic()  + theme(axis.title.y = element_blank())
```

With regards to technical solutions (Figure \@ref(fig:pedteach)) most courses include both practical exercises and live lectures. 

```{r pedteach, fig.cap="Computational strategies used when teaching, number of courses using each strategy."}
ggplot(tmp[tmp$Group == "Strategies",], aes(x=Topic,y=Count)) + geom_bar(stat="identity", width=0.5, fill = "red") + coord_flip()  + theme_classic() + theme(axis.title.y = element_blank())
```

```{r, echo=FALSE, results='hide'}
tmp = courses2[,sel.teaching]
tmp$country = courses2$Country.Edited
tmp2 = tmp %>% group_by(country) %>% summarise_each(list(sum))
tmp2 = data.frame(tmp2)
rownames(tmp2) = tmp2$country
tmp2 = tmp2[,-1]

#pheatmap(t(tmp2>0)+1, cluster_rows = F, fontsize = 6, legend = FALSE)
```



#### Course duration {-}

With regards to course duration, as shown in Figure \@ref(fig:duration), most of the courses are given once yearly for a week. The most common format is to have it on consecutive days. 

```{r duration, echo=FALSE, fig.cap="Counts for questions related to course duration, repetetiveness, and wheather the course is given on consecutive days." }
sel.duration = grep("Duration", colnames(courses2))


tmp = data.frame(Count = colSums(courses2[,sel.duration]))
rownames(tmp) = sub("Duration : ","",rownames(tmp))
tmp$Topic = factor(rownames(tmp),levels = rownames(tmp))
tmp$Group = c(rep("Course days",5),rep("Consecutive",2),rep("Times per year",3))
ggplot(tmp, aes(x=Topic,y=Count, fill = Group)) + geom_bar(stat="identity", width=0.5) + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())
```



#### Participants {-}

The number of participants per course instance is summarized in Figure \@ref(fig:participants). The most common is that each course includes 20-40 participants. 

```{r participants, fig.cap="Number of participants per course"}
sel.nS = grep("nS", colnames(courses2))


tmp = data.frame(count = colSums(courses2[,sel.nS]))
rownames(tmp) = sub("nStudents...","",rownames(tmp))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
ggplot(tmp, aes(x=topic,y=count)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())
```

Entry requirements for the courses (Figure \@ref(fig:entry)) often include coding in R, but also commonly some previous knowledge in NGS analysis. 

```{r entry, fig.cap="Entry requirements used for selecting participants to the courses"}
sel.nS = grep("EntryReq", colnames(courses2))

tmp = data.frame(count = sort(colSums(courses2[,sel.nS])))
rownames(tmp) = sub("EntryReq...","",rownames(tmp))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
ggplot(tmp, aes(x=topic,y=count)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic() + theme(axis.title.y = element_blank())
```



## Conclusions


* Most courses are given once a year, for 1 week with 20-40 students.
* Biggest challenges are non-uniform audiences and different operating systems
* Mainly R based courses.
* Few courses covering other SC-omics than RNA-seq, like ATAC, CITE, VDJ etc.
* For spatial data, mainly visium covered in courses.




```{r, echo=FALSE, results='hide'}
sessionInfo()
```

