---
title: "Training Survey Overview"
format: 
  html:
    toc: true
    number-sections: true
    css: styles.css
    fig-align: center
    fig-width: 8
    fig-height: 5.5 
    code-tools: true
editor: visual
execute: 
  echo: false
  message: false
  warning: false
  error: false
---

```{r}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(xlsx))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(pheatmap))
suppressPackageStartupMessages(library(reactable))
suppressPackageStartupMessages(library(htmltools))
```

```{r, echo=FALSE}
data = read.xlsx("ELIXIR SCO Training survey (rÃ©ponses).xlsx", sheetIndex = 1, header = F)
colnames = as.character(data[1,])
data = data[-1,]

```

## Summary by responses

#### Responses per country

```{r, echo=FALSE}

data$Country = data[,4]
data$Country = sub("ELIXIR-","", data$Country)
data$Country = sub("FRANCE","France", data$Country)
data$Country = sub("The ","", data$Country)
data$Country[grep("UK", data$Country)] = "United Kingdom"
data$Country[grep("German", data$Country)] = "Germany"
data$Country[grep("United States", data$Country)] = "USA"
data$Country[grep("INB Spain", data$Country)] = "Spain"

t = table(data$Country)
data = data[order(data$Country),]
data$nCountry = paste(data$Country, unlist(sapply(t, function(x) 1:x)), sep = "-")

tmp = data.frame(table(data$Country))
colnames(tmp) = c("Country","Counts")
ggplot(tmp, aes(x=Country,y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + theme_classic() + coord_flip()

all.countries = unique(data$Country)
```

```{r, echo=FALSE, results='hide'}
# Responses with no country
a = which(is.na(data[,5]))

b = grep("None", data[,5])

cat("No courses listed for ", paste(data$Country[c(a,b)], collapse = ", "))
```

#### Pedagogical Challenges

TODO! Fix the parsing of others into own category!

```{r, echo=FALSE}
tmp = data.frame(sort(table(unlist(strsplit(data[,81],", ")))))
tmp = tmp[!grepl("Not sure yet - it will run for the first time in July", tmp$Var1),]
tmp = tmp[!grepl("especially",tmp$Var1),]
colnames(tmp) = c("Response","Counts")
# wrap long labels
tmp$Response = str_wrap(tmp$Response, width = 40)
# order by frequency
tmp$Response = factor(tmp$Response, levels = rev(tmp$Response[order(tmp$Counts, decreasing = TRUE)]))
p = ggplot(tmp, aes(x=Response, y=Counts)) + 
  geom_bar(stat="identity", width=0.5, fill = "blue") + 
  coord_flip() + 
  theme_classic() + 
  theme(axis.text.y = element_text(size = 12)) +
  labs(x = "Pedagogical challenges")
p
ggsave("figure/pedagogical_challenges.pdf", p, width = 10, height = 8)
ggsave("figure/pedagogical_challenges.png", p, width = 10, height = 8, dpi = 300)
```

#### Technical Challenges

```{r, echo=FALSE, message=FALSE, results='hide', warning=FALSE}
tmp = data.frame(sort(table(unlist(strsplit(data[,82],"Issues | Data")))), stringsAsFactors = F)
# remove empty
tmp = tmp[nchar(as.character(tmp$Var1))>0,]
# remove comma at the end
tmp$Var1 = gsub(",\\s*$", "", as.character(tmp$Var1))
# now sum labels with same name 
tmp = aggregate(Freq ~ Var1, data = tmp, sum)
tmp = tmp[order(tmp$Freq, decreasing = TRUE),]
# remove specific line
tmp = tmp[!grepl("Not sure yet - it will run for the first time in July", tmp$Var1),]
# filter for counts > 1
tmp = tmp[tmp$Freq > 1,]

#add back the "Issues"
starts = c("on", "in", "due", "with")
is.issue = rowSums(sapply(starts, function(x) startsWith(as.character(tmp$Var1),x)))
tmp$Var1 = as.character(tmp$Var1)
tmp$Var1[is.issue>0] = paste0("Issues ",as.character(tmp$Var1[is.issue>0]))
# max length 80
tmp$Var1 = substr(tmp$Var1,1,80)
# order by frequency
tmp$Var1 = factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])

colnames(tmp) = c("Response","Counts")
# wrap long labels
tmp$Response = str_wrap(tmp$Response, width = 40)
# order by frequency
tmp$Response = factor(tmp$Response, levels = rev(tmp$Response[order(tmp$Counts, decreasing = TRUE)]))
p = ggplot(tmp, aes(x=Response, y=Counts)) + 
  geom_bar(stat="identity", width=0.5, fill = "blue") + 
  coord_flip() + 
  theme_classic() + 
  theme(axis.text.y = element_text(size = 12)) +
  labs(x = "Technical challenges")
p
# save in both formats
ggsave("figure/technical_challenges.pdf", p, width = 10, height = 8)
ggsave("figure/technical_challenges.png", p, width = 10, height = 8, dpi = 300)
```

TODO! Fix the parsing of others into own category!

```         
```

```{r, echo=FALSE, results='hide'}
# Parse information by course

#Instead of listing results by the respondents, extract the information from each individual course. 

#For each course, parse the info in all parts of the questions, also for "Rising need" or "I can teach"

parse_course_url = function(x){
  s = strsplit(x,"\n")[[1]]
  s = gsub("Course *#[0-9] *[:-] *", "",s)
  s = s[nchar(s)>1]
  return(s)
}


options = c("Course #1", "Course #2", "Course #3", "Course #4", "Rising need", "I can teach")
#parse sections 2-11, skipping 7
section.idx = c(2:6,8:11)
section.trans = c("Teacher","Duration","nStudents", "SCO", "SRT","EntryReq","Strategies","Compute", "Topics")
names(section.trans)=section.idx

option = sapply(colnames, str_extract, "\\[.*\\]")
option = gsub("\\]", "", option)
option = gsub("\\[", "", option)
sec = sapply(colnames, str_extract ,"^\\d+")
new.name = paste(section.trans[sec],option, sep = " : ")
new.name[is.na(option)] = colnames[is.na(option)]
colnames(data) = new.name

parse_line = function(x){
  urls = parse_course_url(x[,5])
  datasets = parse_course_url(x[,37])
  email = x[,2]
  s = sapply(options, grepl, x)
  s = apply(s,2, function(y) new.name[y])
  s = lapply(s, function(y) y[!grepl("^\\d",y)]) # remove names starting with number
  
  courses = s[grepl("Course", names(s))]  
  courses = courses[sapply(courses,length)>0]
  nC = length(courses)
  if(nC == 0){
    return(list(country=x[,85],name=x[,86], needs=s$`Rising need`, urls = urls, courses = NULL, email = email))
  }
  
  names(courses) = paste(x[,86], names(courses), sep = ":")
  courses = lapply(courses, function(y) c(y, paste0("Country : ",x[,85])))
  courses = lapply(courses, function(y) c(y, paste0("Email : ",x[,2])))
  if (length(urls) != length(courses)){
    print("Different number of urls. ")
    print(email)
    print(urls)
    print(names(courses))
  }
  if (length(datasets) != length(courses)){
    print("Different number of datasets ")
    print(email)
    print(datasets)
    print(names(courses))
  }
  for (i in 1:length(courses)){
    courses[[i]] = c(courses[[i]], paste0("Url : ", urls[min(i, length(urls))]))
    courses[[i]] = c(courses[[i]], paste0("Dataset : ", datasets[min(i, length(datasets))]))
  }
  
  return(list(country=x[,85],name=x[,86], needs=s$`Rising need`, urls = urls, courses = courses))
   
}


all.data = list()
for (i in 1:nrow(data)){
  all.data[[i]] = parse_line(data[i,])
}
```

```{r, echo=FALSE, results='hide'}
#OBS! USA-1 - same course for 2019,20,21,22 - only one url.


#Comment:
#All other courses on single cell I know are on glittr.org: https://glittr.org/?search=single+cell&per_page=25&sort_by=stargazers&sort_direction=desc

#Multiple galaxyproject entries from Netherlands possibly pointing to the same course.

# One of the Dutch courses is the resource page https://www.singlecell.nl/home, it has all topics included in the list. Remove from summary stats.
```

```{r,  echo=FALSE}
courses = sapply(all.data, function(x) x$courses)
courses = unlist(courses, recursive = F)

all.opts = new.name[!grepl("^\\d", new.name)][-c(1:4)]
all.opts = all.opts[-75]

stats = Reduce(rbind,lapply(courses, function(x) all.opts %in% x))
colnames(stats) = all.opts
rownames(stats) = names(courses)
stats = stats + 0
stats = t(stats)

annot = data.frame(country = sapply(strsplit(names(courses),"-"), function(x) x[1]))
rownames(annot) = names(courses)
```

```{r, echo=FALSE}
# Topics

sel.topics = c(grep("SCO", rownames(stats)), grep("SRT", rownames(stats)), grep("Topics", rownames(stats)))



#pheatmap(stats[sel.topics,], cluster_rows = F, fontsize = 6, annotation_col = annot)
```

```{r, echo=FALSE}
# Grouped by country
course2country = lapply(courses, function(x) gsub("Country : ", "", x[grepl("Country",x)]))

tmp = data.frame(t(stats))
tmp$Country = course2country

tmp = tmp[rownames(tmp) != "Netherlands-5:Course #2",]

tmp2 = tmp %>% group_by(Country) %>% summarise_each(list(sum))

stats.country = data.frame(tmp2)
rownames(stats.country) = tmp2$Country
stats.country = stats.country[,-1]
stats.country = t((stats.country>0) + 0)

#pheatmap(stats.country[sel.topics,], cluster_rows = F, fontsize = 6)
```

```{r,  echo=FALSE}
#### Teaching methods
sel.teaching = c(grep("Strategies", rownames(stats)), grep("Compute", rownames(stats)))

#pheatmap(stats[sel.teaching,], cluster_rows = F, fontsize = 6, annotation_col = annot)

# Grouped by country
#pheatmap(stats.country[sel.teaching,], cluster_rows = F, fontsize = 6)
```

### Technologies with a rising need

Areas where the respondents sees a rising need, grouped by country

SCO = Single Cell Omics, SRT = Spatially Resolved Transcriptomics

```{r, echo=FALSE, fig.height=5}
needs = lapply(all.data, function(x) x$needs)
countries = unlist(lapply(all.data, function(x) x$country))

s = split(needs, countries)
s = lapply(s, unlist)

all.cat = rownames(stats)[c(grep("SCO", rownames(stats)), grep("SRT", rownames(stats)))]

need.stats = Reduce(cbind, lapply(s, function(x) all.cat %in% x)) + 0
rownames(need.stats) = all.cat
colnames(need.stats) = names(s)

pheatmap(need.stats, cluster_rows = F, legend_breaks = c(0,1), legend_labels = c("no","yes"))
```

```{r, echo=FALSE}
#### Print to csv
all.courses = unlist(lapply(all.data, function(x) x$courses), recursive = F)

course.names = colnames(stats)

sel.columns = c("Country","Email","Url","Dataset")
pattern = paste(sel.columns, collapse = "|")

extra = Reduce(rbind, lapply(all.courses, function(x) x[grepl(pattern,x)]))
colnames(extra) = sel.columns


out = data.frame(cbind(extra),t(stats))
rownames(out) = colnames(stats)
write.csv(out, "parsed_courses.csv")
```

## Summary by course

Instead of listing results by the respondents, extract the information from each individual course. Each response contains up to 4 courses.

Manual filtering of duplicate course instances, correct country of origin and examples of entries that are not really courses.

### Table of all courses

```{r, echo=FALSE}
courses2 = read.table("Training_survey_parsed_courses - parsed_courses.tsv", header = T, sep = "\t", comment.char = "", row.names = 1, as.is = T, quote = "")

# remove duplicates and non-courses
courses2 = courses2[nchar(courses2$Is.duplicate) ==0,]
courses2 = courses2[nchar(courses2$Not.a.course) ==0,]
```

In total `r nrow(courses2)` courses are included.

```{r}
table.data = courses2[grepl("Yes",courses2$Online.material),]
table.data = table.data[,c(2,4,7,8,17:87)]
table.data$Url = sub("Url : ", "",table.data$Url)

# remove strategies
table.data = table.data[,!grepl("Strategies",colnames(table.data))]

# group the topics.


reactable(
  table.data,
  wrap = FALSE,
  resizable = TRUE,
  minRows = 10,
  elementId = "tbl"
)
```

```{ojs}
// Create an Observable value that automatically tracks the table's filtered data
filteredData = Generators.observe(change => {
  return Reactable.onStateChange('tbl-input', state => {
    change(state.sortedData)
  })
})
```

```{r}
ojs_define(tbl = table.data)
```

```{ojs}
viewof Coutry = Inputs.range(
  [32, 50], 
  {value: 35, step: 1, label: "Bill length (min):"}
)
viewof Country = Inputs.checkbox(
  unique(table.data$Country.Edited), 
  { value: unique(table.data$Country.Edited), 
    label: "Country:"
  }
)
```

```{r}
# Select input filter with an "All" default option
selectFilter <- function(tableId, style = "width: 100%; height: 100%;") {
  function(values, name) {
    tags$select(
      # Set to undefined to clear the filter
      onchange = sprintf("
        const value = event.target.value
        Reactable.setFilter('%s', '%s', value === '__ALL__' ? undefined : value)
      ", tableId, name),
      # "All" has a special value to clear the filter, and is the default option
      tags$option(value = "__ALL__", "All"),
      lapply(unique(values), tags$option),
      "aria-label" = sprintf("Filter %s", name),
      style = style
    )
  }
}


reactable(
  table.data,
  columns = list(
    Country.Edited = colDef(
      filterInput = selectFilter("tbl-input")
    ),
    Course.year = colDef(
      filterInput = selectFilter("tbl-input")
    )
  ),
  filterable = TRUE,
  wrap = FALSE,
  resizable = TRUE,
  defaultPageSize = 10,
  minRows = 5,
  elementId = "tbl-input"
)
```

### Courses given per country

```{r, echo=FALSE}

tmp = data.frame(table(courses2$Country.Edited))
colnames(tmp) = c("Country","Counts")

ggplot(tmp, aes(x=Country,y=Counts)) + geom_bar(stat="identity", width=0.5, fill = "blue") + theme_classic() + coord_flip()

```

### Topics / Technologies - By course

TODO! Fix the names with ...

```{r}
sel.topics = c(grep("SCO", colnames(courses2)), grep("SRT", colnames(courses2)), grep("Topics", colnames(courses2)))

annot = data.frame(country = courses2$Country.Edited)
annot$country = gsub("Country : ","", annot$country)
rownames(annot) = rownames(courses2)

```

```{r, echo=FALSE}
pheatmap(t(courses2[,sel.topics]), cluster_rows = F, cluster_cols = T, fontsize = 6, annotation_col = annot, legend_breaks = c(0,1), legend_labels = c("no","yes"))

```

### Topics / Technologies - Number of courses

```{r}

tmp = data.frame(count = sort(colSums(courses2[,sel.topics])))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
tmp$group = unlist(lapply(strsplit(rownames(tmp),"\\.."), function(x) x[1]))
ggplot(tmp, aes(x=topic,y=count, fill=group)) + geom_bar(stat="identity", width=0.5) + coord_flip() + theme_classic()
```

### Topics / Technologies - By country

```{r}
tmp = courses2[,sel.topics]
tmp$country = courses2$Country.Edited
tmp2 = tmp %>% group_by(country) %>% summarise_each(list(sum))
tmp2 = data.frame(tmp2)
rownames(tmp2) = tmp2$country
tmp2 = tmp2[,-1]
```

```{r, echo=FALSE}
pheatmap(t(tmp2>0)+0, cluster_rows = F, fontsize = 6, legend_breaks = c(0,1), legend_labels = c("no","yes"))

```

### Teaching methods - Computational

```{r}
sel.teaching = c(grep("Strategies", colnames(courses2)), grep("Compute", colnames(courses2)))

tmp = data.frame(count = sort(colSums(courses2[,sel.teaching])))
tmp$group = unlist(lapply(strsplit(rownames(tmp),"\\.."), function(x) x[1]))
tmp = tmp[!grepl("Other",rownames(tmp)),]

tmp$topic = gsub("Strategies...","",rownames(tmp))
tmp$topic = gsub("Compute...","",tmp$topic)
tmp$topic = factor(tmp$topic,levels = tmp$topic)

ggplot(tmp[tmp$group == "Compute",], aes(x=topic,y=count, fill=group)) + geom_bar(stat="identity", width=0.5) + coord_flip()  + theme_classic() 
```

### Teaching methods - Strategies

```{r}
ggplot(tmp[tmp$group == "Strategies",], aes(x=topic,y=count, fill=group)) + geom_bar(stat="identity", width=0.5) + coord_flip()  + theme_classic() 
```

```{r, echo=FALSE, results='hide'}
tmp = courses2[,sel.teaching]
tmp$country = courses2$Country.Edited
tmp2 = tmp %>% group_by(country) %>% summarise_each(list(sum))
tmp2 = data.frame(tmp2)
rownames(tmp2) = tmp2$country
tmp2 = tmp2[,-1]

#pheatmap(t(tmp2>0)+1, cluster_rows = F, fontsize = 6, legend = FALSE)
```

### Course duration

```{r, echo=FALSE}
sel.duration = grep("Duration", colnames(courses2))


tmp = data.frame(count = colSums(courses2[,sel.duration]))
rownames(tmp) = sub("Duration...","",rownames(tmp))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
tmp$group = c(rep("Days",5),rep("Consecutive",2),rep("Yearly",3))
ggplot(tmp, aes(x=topic,y=count, fill = group)) + geom_bar(stat="identity", width=0.5) + coord_flip() + theme_classic()
```

### Participants

```{r, echo=FALSE}
sel.nS = grep("nS", colnames(courses2))


tmp = data.frame(count = colSums(courses2[,sel.nS]))
rownames(tmp) = sub("nStudents...","",rownames(tmp))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
ggplot(tmp, aes(x=topic,y=count)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic()
```

### Entry requirements

```{r, echo=FALSE}
sel.nS = grep("EntryReq", colnames(courses2))

tmp = data.frame(count = sort(colSums(courses2[,sel.nS])))
rownames(tmp) = sub("EntryReq...","",rownames(tmp))
tmp$topic = factor(rownames(tmp),levels = rownames(tmp))
ggplot(tmp, aes(x=topic,y=count)) + geom_bar(stat="identity", width=0.5, fill = "blue") + coord_flip() + theme_classic()
  
```

### Compute resources

```{r}
library(readxl)
library(pheatmap)
library(stringr)

courses2 <- read_excel("Training_survey_parsed_courses.xlsx", sheet = 2)
suppressPackageStartupMessages(library(pheatmap))
env_cols <- grep("^Compute\\.\\.\\.", colnames(courses2), value = TRUE)
heatmap_data <- courses2[, env_cols]
heatmap_data[!is.na(heatmap_data) & heatmap_data != 0] <- 1
heatmap_data[is.na(heatmap_data)] <- 0
rownames(heatmap_data) <- make.unique(as.character(courses2$`Course name`))
colnames(heatmap_data) <- c(
  "Local software installation",
  "Course Server (AWS, HPC, etc.)",
  "Free private Server (Gitpod, GoogleColab)",
  "Galaxy/Chipster infrastructure",
  "Docker",
  "Conda",
  "Rstudio",
  "Jupyter",
  "Other"
)
# Plot the heatmap
pheatmap(
  heatmap_data,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  fontsize_row = 8,
  fontsize_col = 10,
  color = c("white", "brown"),
  legend = FALSE,
  angle_col = 315,
  filename = "figure/compute_resources_heatmap.pdf",
  width = 8,  
  height = 8
)

```

### Topics/technologies

```{r}
library(readxl)
library(pheatmap)
library(stringr)

courses2 <- read_excel("Training_survey_parsed_courses.xlsx", sheet = 2)
suppressPackageStartupMessages(library(pheatmap))
topic_cols <- grep("^(SCO|SRT)\\.\\.\\.", colnames(courses2), value = TRUE)

# Subset the data for the heatmap
topic_heatmap_data <- courses2[, topic_cols]
topic_heatmap_data[!is.na(topic_heatmap_data) & topic_heatmap_data != 0] <- 1
topic_heatmap_data[is.na(topic_heatmap_data)] <- 0
rownames(topic_heatmap_data) <- make.unique(as.character(courses2$`Course name`))

# Optionally, you can prettify the column names if you want
colnames(topic_heatmap_data) <- gsub("^SCO\\.\\.\\.|^SRT\\.\\.\\.", "", colnames(topic_heatmap_data))

colnames(topic_heatmap_data) <- c(
 "scRNAseq",                                    
 "scATACseq",                                        
 "scVDJseq",                                         
 "scCHIPseq",                                        
 "scMETseq",                                         
 "scDNAseq",                                         
 "CITEseq",                                          
 "CyTOF FACS",
 "scPERTURBseq",                                     
 "Multi modal Omics",
 "Spot based SRT e.g 10X Visium",                 
 "Image based SRT e.g 0X Xenium ISS",
 "Targeted proteomics SRT e.g CODEX",             
 "Untargeted proteomics metabolomics SRT e.g MSI",
 "Image analysis SRT e.g HE staining"
)

# Plot the heatmap
pheatmap(
  topic_heatmap_data,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  fontsize_row = 8,
  fontsize_col = 10,
  color = c("white", "brown"),
  legend = FALSE,
  angle_col = 315,
  filename = "figure/topics_heatmap.pdf",
  width = 10,
  height = 8
)

```

## Conclusions

-   Most courses are given once a year, for 1 week with 20-40 students.
-   Biggest challenges are non-uniform audiences and different operating systems
-   Mainly R based courses.
-   Few courses covering other SC-omics than RNA-seq, like ATAC, CITE, VDJ etc.
-   For spatial data, mainly visium covered in courses.

```{r, echo=FALSE, results='hide'}
sessionInfo()
```
